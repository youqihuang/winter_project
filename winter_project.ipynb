{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M-ORmPQDj3n",
        "outputId": "13c8db16-84f1-470c-ce75-1a931fc626f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[[1 'thirtysomething scientists unveil doomsday clock of hair loss']\n",
            " [0\n",
            "  'dem rep. totally nails why congress is falling short on gender, racial equality']\n",
            " [0 'eat your veggies: 9 deliciously different recipes']\n",
            " ...\n",
            " [0\n",
            "  'the most beautiful acceptance speech this week came from a queer korean']\n",
            " [1 'mars probe destroyed by orbiting spielberg-gates space palace']\n",
            " [1 'dad clarifies this not a food stop']]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "df = pd.read_json('/content/drive/MyDrive/Sarcasm_Headlines_Dataset_v2.json', lines = True)\n",
        "df = df.dropna()\n",
        "df = df.drop(df.columns[2], axis=1)\n",
        "df = df.to_numpy()\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijlz8GVbEQHZ",
        "outputId": "2cbfe018-feb7-4fd2-aa95-36c140c56bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p_GToW5sGuFJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYxeo-WNGyBS",
        "outputId": "a00eb47e-a3dc-4ce8-a3f7-f16239b95ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\").to(device)\n",
        "model.cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),  lr= 1e-4 ,  betas=(0, 0.9)  )\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJC2x9LiHbzV",
        "outputId": "9010fdf5-8f1e-4615-d53f-222f271b2942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thirtysomething scientists unveil doomsday clock of hair loss'\n",
            " 'dem rep. totally nails why congress is falling short on gender, racial equality'\n",
            " 'eat your veggies: 9 deliciously different recipes' ...\n",
            " 'area mom raving about phoenix airport'\n",
            " 'seaworld to discontinue great white shark ride'\n",
            " '3-day waiting period leads to far more feasible murder plot']\n",
            "[1 0 0 ... 1 1 1]\n",
            "975\n"
          ]
        }
      ],
      "source": [
        "x = df[:2000, 1]\n",
        "y = df[:2000, 0]\n",
        "print(x)\n",
        "print(y)\n",
        "count = sum(y)\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XHK3q-6qHfUg"
      },
      "outputs": [],
      "source": [
        "def balanced_subsample(x,y,subsample_size=1.0):\n",
        "\n",
        "    class_xs = []\n",
        "    min_elems = None\n",
        "\n",
        "    for yi in np.unique(y):\n",
        "        elems = x[(y == yi)]\n",
        "        class_xs.append((yi, elems))\n",
        "        if min_elems == None or elems.shape[0] < min_elems:\n",
        "            min_elems = elems.shape[0]\n",
        "\n",
        "    use_elems = min_elems\n",
        "    if subsample_size < 1:\n",
        "        use_elems = int(min_elems*subsample_size)\n",
        "\n",
        "    xs = []\n",
        "    ys = []\n",
        "\n",
        "    for ci,this_xs in class_xs:\n",
        "        if len(this_xs) > use_elems:\n",
        "            np.random.shuffle(this_xs)\n",
        "\n",
        "        x_ = this_xs[:use_elems]\n",
        "        y_ = np.empty(use_elems)\n",
        "        y_.fill(ci)\n",
        "\n",
        "        xs.append(x_)\n",
        "        ys.append(y_)\n",
        "\n",
        "    xs = np.concatenate(xs)\n",
        "    ys = np.concatenate(ys)\n",
        "\n",
        "    return xs,ys\n",
        "\n",
        "x, y = balanced_subsample(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCK_A7RHHiw1",
        "outputId": "4c9898eb-f3e5-4eef-e9b8-efe59c10822e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1306]) torch.Size([644])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from torch.utils.data import TensorDataset\n",
        "batch_size = 8\n",
        "num_workers = 32\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "x_train = x_train.tolist()\n",
        "x_test = x_test.tolist()\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "print(y_train.shape, y_test.shape)\n",
        "\n",
        "train_encode = tokenizer(text=x_train, return_tensors='pt', add_special_tokens=True, padding=True, truncation = True, max_length = 512)\n",
        "test_encode = tokenizer(text=x_test, return_tensors='pt', add_special_tokens=True, padding=True, truncation = True, max_length = 512)\n",
        "\n",
        "train_data = TensorDataset(train_encode['input_ids'], train_encode['attention_mask'], y_train)\n",
        "test_data = TensorDataset(test_encode['input_ids'], test_encode['attention_mask'], y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler= SequentialSampler(train_data),\n",
        "                        batch_size=batch_size, pin_memory=num_workers>0, num_workers=num_workers)\n",
        "val_dataloader = DataLoader(test_data, sampler= SequentialSampler(test_data),\n",
        "                        batch_size=batch_size, pin_memory=num_workers>0, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8DW2zdd_Hmrf"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, val_dataloader, num_epochs):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[0].to(device)\n",
        "        input_attn = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids,attention_mask=input_attn).logits\n",
        "        l = loss(logits,labels)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def val(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            input_attn = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "            logits = model(input_ids, attention_mask=input_attn).logits\n",
        "\n",
        "            # Get predicted labels\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # Update lists\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate and print classification report\n",
        "    report = classification_report(all_labels, all_predictions)\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uJX11i7WHpyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19e558c-688c-4891-a7e5-70b1f071d8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.95      0.88       320\n",
            "           1       0.94      0.79      0.86       324\n",
            "\n",
            "    accuracy                           0.87       644\n",
            "   macro avg       0.88      0.87      0.87       644\n",
            "weighted avg       0.88      0.87      0.87       644\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train(train_dataloader, val_dataloader, 5)\n",
        "val(model, val_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}